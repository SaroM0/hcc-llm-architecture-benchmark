api:
  base_url: ${OPENROUTER_BASE_URL}
  api_key: ${OPENROUTER_API_KEY}
  timeout_s: 120
  retries: 3
  headers: {}

# =============================================================================
# MODEL DEFINITIONS
# =============================================================================
# Large models: High-capacity state-of-the-art models (upper-bound reference)
# Small models: Resource-efficient models (deployable/cost-constrained)
# =============================================================================

models:
  # --- LARGE MODELS (5) ---
  gpt52:
    id: openai/gpt-5.2
    class: large
    defaults:
      temperature: 0.2
      max_tokens: 2048
  gemini3pro:
    id: google/gemini-3-pro-preview
    class: large
    defaults:
      temperature: 0.2
      max_tokens: 2048
  mistral_large_2512:
    id: mistralai/mistral-large-2512
    class: large
    defaults:
      temperature: 0.2
      max_tokens: 2048
  glm47:
    id: z-ai/glm-4.7
    class: large
    defaults:
      temperature: 0.2
      max_tokens: 2048
  claude_opus_4:
    id: anthropic/claude-opus-4
    class: large
    defaults:
      temperature: 0.2
      max_tokens: 2048

  # --- SMALL MODELS (5) ---
  qwen3_vl_30b:
    id: qwen/qwen3-vl-30b-a3b-thinking
    class: small
    defaults:
      temperature: 0.2
      max_tokens: 2048
  gemma3_27b:
    id: google/gemma-3-27b-it
    class: small
    defaults:
      temperature: 0.2
      max_tokens: 2048
  ministral_14b:
    id: mistralai/ministral-14b-2512
    class: small
    defaults:
      temperature: 0.2
      max_tokens: 2048
  nemotron_3_nano:
    id: nvidia/nemotron-3-nano-30b-a3b
    class: small
    defaults:
      temperature: 0.2
      max_tokens: 2048
  gpt_oss_20b:
    id: openai/gpt-oss-20b
    class: small
    defaults:
      temperature: 0.2
      max_tokens: 2048

# =============================================================================
# MODEL GROUPS FOR EXPERIMENTS
# =============================================================================
groups:
  large: [gpt52, gemini3pro, mistral_large_2512, glm47, claude_opus_4]
  small: [qwen3_vl_30b, gemma3_27b, ministral_14b, nemotron_3_nano, gpt_oss_20b]
  all: [gpt52, gemini3pro, mistral_large_2512, glm47, claude_opus_4, qwen3_vl_30b, gemma3_27b, ministral_14b, nemotron_3_nano, gpt_oss_20b]
  # Best performing models from each class
  best_large: [gpt52]
  best_small: [qwen3_vl_30b]

# =============================================================================
# ROLE DEFAULTS
# =============================================================================
roles:
  # A1: Oneshot (no RAG)
  oneshot: qwen3_vl_30b

  # A2: Oneshot RAG (generic)
  oneshot_rag: qwen3_vl_30b

  # A3: Multi-agent Consensus RAG for large models
  consensus_large: gpt52

  # A4: Multi-agent Consensus RAG for small models
  consensus_small: qwen3_vl_30b

  # Evaluation
  judge: gpt52
